{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Загрузим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_PS = pd.read_csv('positive.csv',sep=';',error_bad_lines=False, header=None).iloc[:,[3,4]]\n",
    "text_NG = pd.read_csv('negative.csv',sep=';',error_bad_lines=False, header=None).iloc[:,[3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_PS[4]=1 # positive\n",
    "text_NG[4]=0 # negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114911, 2) (111923, 2)\n"
     ]
    }
   ],
   "source": [
    "# проверим на сбалансированность\n",
    "print(text_PS.shape,text_NG.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# обьеденим для удобства работы\n",
    "data=pd.concat([text_PS,text_NG])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Уберем теги @ и RE\n",
    "data[3] = data[3].map(lambda x:re.sub(r'[R][T]\\s+[@]\\w+[:]\\s*|[@]\\w+\\s+','', x))\n",
    "# заменим ссылки на SH_T_T_P\n",
    "# заменим цифры на D_G_TII\n",
    "data[3] = data[3].map(lambda x:re.sub(r'\\d\\w*','d_g_t', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   3  4\n",
      "0  хоть я и школота, но поверь, у нас то же самое...  1\n",
      "1  Да, все-таки он немного похож на него. Но мой ...  1\n",
      "2             Ну ты идиотка) я испугалась за тебя!!!  1\n",
      "3  \"Кто то в углу сидит и погибает от голода, а м...  1\n",
      "4  Вот что значит страшилка :D\\nНо блин,посмотрев...  1\n",
      "5  ну любишь или нет? — Я не знаю кто ты бля:D ht...  1\n",
      "6  Ох,d_g_t :D ну это конечно же . Чтобы у нее бы...  1\n",
      "7  У тебя есть ухажёр? Нет - мои уши не кто не жр...  1\n",
      "8            Поприветствуем моего нового читателя ;)  1\n",
      "9  Теперь у меня есть частичка Сиднея :) #Sydney ...  1\n"
     ]
    }
   ],
   "source": [
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer (inp):\n",
    "    return re.split(r'[;?!,\\s]',inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text\n",
    "vctr = sklearn.feature_extraction.text.CountVectorizer(min_df=10,max_df=0.8,tokenizer=my_tokenizer)\n",
    "#vctr = sklearn.feature_extraction.text.CountVectorizer(tokenizer=my_tokenizer)\n",
    "# нужен свой шаблон token_pattern=\n",
    "# min_df=5 слово должно встречаться минимум в 5 докумнтах\n",
    "# max_df=0.9 уберем слова которые встречаются более чем в 90 процентах докуметов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vect = vctr.fit_transform(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226834, 17797)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vctr.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vctr.vocabulary_.get(':-)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF.IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vctr_tfidf = sklearn.feature_extraction.text.TfidfTransformer()\n",
    "data_tfidf = vctr_tfidf.fit_transform(data_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226834, 17797)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(data_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим на тестовую и валидационную\n",
    "y=data[4]\n",
    "del data[4]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_tfidf, y, test_size=0.33, random_state=442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151978, 17797)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классифицируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Баес\n",
    "import sklearn.naive_bayes\n",
    "bb=sklearn.naive_bayes.MultinomialNB(alpha=5)\n",
    "bb.fit(X_train, y_train)\n",
    "predicted=bb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]Wall time: 1h 50min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC(kernel=\"linear\", verbose=True)\n",
    "svm.fit(X_train, y_train)\n",
    "predicted=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценим качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50721385059313884"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Баес\n",
    "0.7476 - чистый\n",
    "0.7390 - убрал хештеги и числа\n",
    "0.7380 + CountVectorizer(min_df=5,max_df=0.9)\n",
    "0.8387 + токенайзер который пропускает варианты с :-) и :-( c пробелом\n",
    "0.8452 + токенайзер который пропускает варианты с :-) и :-( c пробелом и тд\n",
    "0.8617 + токенайзер который пропускает варианты с :-) и :-( c r'[;?!,\\s]'\n",
    "0.8457 - только свой токенайзер \n",
    "--- чем болше данных тем лучше работает\n",
    "\n",
    "#SVM\n",
    "0.8227 linear C=0.025 \\хештеги и числа и min_df=5,max_df=0.9\n",
    "0.8569 linear C=1 \\хештеги и числа и min_df=10,max_df=0. //55 min ФИНАЛ\n",
    "0.50 rbf C=1 \\хештеги и числа и min_df=10,max_df=0. //1:55 min\n",
    "--- явно лучше класифицирует на меньшем обьеме фич лучший кандидат на финальный тюниг\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
