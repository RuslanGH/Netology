{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данного задания, студент должен создать и оценить 4 типа рекомендательных систем:\n",
    "* Item-based collaborative filtering RS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Детальное описание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Данные: \n",
    "Датасет представлен множеством отзывов к компьютерным играм (объектам) от пользователей Amazon. Каждый отзыв представлен в виде JSON-структуры со следующими полями:\n",
    "* идентификатор пользователя - reviewerID\n",
    "* идентификатор объекта - asin\n",
    "* текст отзыва - reviewText\n",
    "* рейтинг - overall\n",
    "* время публикации обзора - unixReviewTime\n",
    "* другие поля, не использованные автором этого блокнота (смотри полное описание JSON [тут](http://jmcauley.ucsd.edu/data/amazon/))\n",
    "\n",
    "У каждого объекта есть как минимум 5 отзывов, каждый пользователь написал как минимум 5 отзывов. \n",
    "#### Цель: \n",
    "Построить рекомендательную систему, предсказывающую объекты, которые пользователь приобретет в ближайшем будущем. Для упрощения мы считаем, что пользователь приобрел объект, если он написал про него отзыв.\n",
    "#### Подготовка данных:\n",
    "Данные разделены на тренировочную и тестовую выборки по времени публикации отзывов. Первые 80% данных (более старые) используются как тренировочная выборка, остальные - как тестовая. \n",
    "\n",
    "Построение рекомендательной системы (т.е., выбор и тренировка моделей, оптимизация параметров и т.д.) осуществляется **только** с использованием тренировочной выборки. Все параметры, использованные в моделях, **должны быть** получены или объяснены с помощью тренировочных данных. Студент вправе использовать тренировочную выборку как его душе угодно. \n",
    "\n",
    "Тестирующая выборка используется **только** для оценки рекомендательной системы.\n",
    "\n",
    "Для построения рекомендательных моделей также можно использовать JSON-поля из датасета, неиспользованные автором этого блокнота.\n",
    "#### Оценка качества рекомендательной системы\n",
    "Цель рекомендательной системы - посоветовать пользователю объекты, которые он захочет приобрести. Для оценки качества такой системы мы воспользуемся метрикой `hit-ratio (HR)`. \n",
    "\n",
    "$$\n",
    "HR = \\frac{1}{|U_T|}\\sum_{u \\in U_T} \\mathrm{I}(Rel_u \\cap Rec_u)\n",
    "$$\n",
    "\n",
    "* $U_T$ - множество пользователей из тестовой выборки\n",
    "* $Rec_u$ - множество объектов, рекомендованных пользователю $u$ \n",
    "* $Rel_u$ - множество объектов, оцененных пользователем $u$ в тестовой выборке\n",
    "* $\\mathrm{I}(Rel_u \\cap Rec_u)$ - бинарная функция-индикатор. Функция возвращает 1 если $Rel_u \\cap Rec_u \\ne \\emptyset$, иначе 0\n",
    "\n",
    "$HR=1$ если для каждого пользователя мы рекомендовали хотя бы один релевантный объект. Так как обычно пользователи просматривают только первые $N$ рекомендаций, мы будем считать метрику $HR@N$, где $N=10$ (т.е. множество $Rec_u$ будет содержать только 10 объектов). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Условные обозначения\n",
    "* `uid` - идентификатор пользователя\n",
    "* `iid` - идентификатор объекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Games RSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# импорты, которые точно понадобятся\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import normalize, binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JSON_DATA_PATH = \"data/Video_Games_5.json\"\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def iter_json_data(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            yield data\n",
    "            \n",
    "def get_data_frame():\n",
    "    uid_to_id = {}\n",
    "    iid_to_id = {}\n",
    "    \n",
    "    cols = [\"uid\", \"iid\", \"review\", \"rating\", \"dt\"]\n",
    "    rows = []\n",
    "    for d in iter_json_data(JSON_DATA_PATH):\n",
    "        uid = uid_to_id.setdefault(d[\"reviewerID\"], len(uid_to_id))\n",
    "        iid = iid_to_id.setdefault(d[\"asin\"], len(iid_to_id))\n",
    "        review = d[\"reviewText\"]\n",
    "        rating = float(d[\"overall\"])\n",
    "        dt = int(d[\"unixReviewTime\"])\n",
    "        rows.append((uid, iid, review, rating, dt))\n",
    "        \n",
    "    return pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Installing the game was a struggle (because of...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1341792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>If you like rally cars get this game you will ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1372550400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1st shipment received a book instead of the ga...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1403913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I got this version instead of the PS3 version,...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1315958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I had Dirt 2 on Xbox 360 and it was an okay ga...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1308009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  iid                                             review  rating  \\\n",
       "0    0    0  Installing the game was a struggle (because of...     1.0   \n",
       "1    1    0  If you like rally cars get this game you will ...     4.0   \n",
       "2    2    0  1st shipment received a book instead of the ga...     1.0   \n",
       "3    3    0  I got this version instead of the PS3 version,...     3.0   \n",
       "4    4    0  I had Dirt 2 on Xbox 360 and it was an okay ga...     4.0   \n",
       "\n",
       "           dt  \n",
       "0  1341792000  \n",
       "1  1372550400  \n",
       "2  1403913600  \n",
       "3  1315958400  \n",
       "4  1308009600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_data_frame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min-max количество объектов на пользователя: 5 773\n",
      "min-max количество пользователей на объект: 5 802\n"
     ]
    }
   ],
   "source": [
    "print(\"min-max количество объектов на пользователя:\", \n",
    "      df.groupby(\"uid\").iid.nunique().min(), df.groupby(\"uid\").iid.nunique().max())\n",
    "print(\"min-max количество пользователей на объект:\", \n",
    "      df.groupby(\"iid\").uid.nunique().min(), df.groupby(\"iid\").uid.nunique().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверяем, есть ли случаи, когда один и тот же пользователь оставляет отзывы на один и тот же объект\n",
    "df.groupby([\"uid\", \"iid\"]).review.count().unique()  # ура, таких случаев нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество объектов: 10672\n",
      "Количество пользователей: 24303\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество объектов:\", df.iid.unique().size)\n",
    "print(\"Количество пользователей:\", df.uid.unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_df_by_dt(df, p=0.8):\n",
    "    \"\"\"Функция разбивает df на тестовую и тренировочную выборки по времени \n",
    "    публикации отзывов (значение времени в поле dt)\n",
    "    \n",
    "    :param p: персентиль значений dt, которые образуют тренировочную выборку. Например p=0.8 означает, что в \n",
    "    тренировочной части будут отзывы, соответствующие первым 80% временного интервала \n",
    "    :return: два pd.DataFrame объекта\n",
    "    \"\"\"\n",
    "    border_dt = df.dt.quantile(p)\n",
    "    print(\"Min=%s, border=%s, max=%s\" % (df.dt.min(), border_dt, df.dt.max()))\n",
    "    training_df, test_df  = df[df.dt <= border_dt], df[df.dt > border_dt]\n",
    "    print(\"Размер до очистки:\", training_df.shape, test_df.shape)\n",
    "    # удаляем из тестовых данных строки, соответствующие пользователям или объектам, \n",
    "    # которых нет в тренировочных данных \n",
    "    # (пользователи - избегаем проблем для персональных систем, объекты - для всех)\n",
    "    test_df = test_df[test_df.uid.isin(training_df.uid) & test_df.iid.isin(training_df.iid)]\n",
    "    print(\"Размер после очистки:\", training_df.shape, test_df.shape)\n",
    "    return training_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min=939859200, border=1377129600.0, max=1405987200\n",
      "Размер до очистки: (185427, 5) (46353, 5)\n",
      "Размер после очистки: (185427, 5) (19174, 5)\n"
     ]
    }
   ],
   "source": [
    "training_df, test_df = split_df_by_dt(df)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_df(df, min_review_per_uid, min_review_per_iid):\n",
    "    \"\"\"Функция удаляет из df строки, соответствующие пользователям и объектам, \n",
    "    у которых меньше min_review_per_uid и min_review_per_iid отзывов соответственно\n",
    "    \"\"\"\n",
    "    _df = df.copy()\n",
    "    while True:\n",
    "        review_per_uid = _df.groupby(\"uid\").review.count()\n",
    "        bad_uids = review_per_uid[review_per_uid < min_review_per_uid].index\n",
    "    \n",
    "        review_per_iid = _df.groupby(\"iid\").review.count()\n",
    "        bad_iids = review_per_iid[review_per_iid < min_review_per_iid].index\n",
    "        \n",
    "        if bad_uids.shape[0] > 0 or bad_iids.shape[0] > 0:\n",
    "            _df = _df[(~_df.uid.isin(bad_uids)) & (~_df.iid.isin(bad_iids))]\n",
    "        else:\n",
    "            break\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Метрика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для упрощения тестирования предлагается использовать словарь следующего типа:\n",
    "\n",
    "```python\n",
    "recs = {\n",
    "    uid_1: {\n",
    "        iid_1: score_11,\n",
    "        iid_2: score_12,\n",
    "        ...\n",
    "    },\n",
    "    uid_2: {\n",
    "        iid_1: score_21,\n",
    "        iid_2: score_22,\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "где `uid_i` - идентификатор тестового пользователя, `iid_j` - идентификатор рекомендованного объекта, а `score_ij` - предсказанный рейтинг/вес объекта `j` для пользователя `i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hit_ratio(recs_dict, test_dict):\n",
    "    \"\"\"Функция считает метрику hit-ration для двух словарей\n",
    "    :recs_dict: словарь рекомендаций типа {uid: {iid: score, ...}, ...}\n",
    "    :test_dict: тестовый словарь типа {uid: {iid: score, ...}, ...}\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    for uid in test_dict:\n",
    "        if set(test_dict[uid].keys()).intersection(recs_dict.get(uid, {})):\n",
    "            hits += 1\n",
    "    return hits / len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_dict(test_df):\n",
    "    \"\"\"Функция, конвертирующая тестовый df в словарь\n",
    "    \"\"\"\n",
    "    test_dict = {}\n",
    "    for t in test_df.itertuples():\n",
    "        test_dict.setdefault(t.uid, {})\n",
    "        test_dict[t.uid][t.iid] = t.rating\n",
    "    return test_dict\n",
    "\n",
    "test_dict = get_test_dict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item-based collaborative filtering RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item-based CF основан на идее, что пользователь предпочтет объекты, похожие на те, что он приобретал ранее. Данные в CF модели представлены матрицей `user x item`, где ячейка матрицы соответствует рейтингу, который пользователь поставил объекту. Вместо рейтингов в матрице могут быть вероятности (т.е. вероятность, что пользователь воспользуется объектом). Для работы модели необходимо построить матрицу `item x item` схожести объектов. Обычно для построения матрицы схожести используется исходная матрица `user x item`. Чтобы уменьшить шумы в матрице схожести, для каждого объекта хранят только $K$ наиболее похожих объектов.\n",
    "\n",
    "В простейшем случае рекомендации строятся путем нахождения объектов с наибольшим значением предсказанного рейтинга:\n",
    "$$\\hat{r}_{ui} = \\frac{\\sum_{j \\in I_u} r_{uj} * sim(j, i)}{\\sum_{j \\in I_u} r_{uj}}$$\n",
    "\n",
    "* $I_u$ - множество объектов, оцененных пользователем\n",
    "* $sim(j, i)$ - схожесть между объектами $j$ и $i$\n",
    "\n",
    "Часто из финальных рекомендаций для пользователя $u$ исключаются объекты $I_u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# вспомогательные функции, которые могут пригодиться при построении Item-based CF\n",
    "def nullify_main_diagonal(m):\n",
    "    positions = range(m.shape[0])\n",
    "    eye = csr_matrix((np.ones(len(positions)), (positions, positions)), m.shape)\n",
    "    return m - m.multiply(eye)\n",
    "\n",
    "\n",
    "def get_topk(matrix, top, axis=1):\n",
    "    \"\"\"Converts source matrix to Top-K matrix\n",
    "    where each row or column contains only top K values\n",
    "\n",
    "    :param matrix: source matrix\n",
    "    :param top: number of top items to be stored\n",
    "    :param axis: 0 - top by column, 1 - top by row\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    if axis == 0:\n",
    "        matrix = matrix.T.tocsr()\n",
    "\n",
    "    for row_id, row in enumerate(matrix):\n",
    "        if top is not None and row.nnz > top:\n",
    "            top_args = np.argsort(row.data)[-top:]\n",
    "\n",
    "            rows += [row_id] * top\n",
    "            cols += row.indices[top_args].tolist()\n",
    "            data += row.data[top_args].tolist()\n",
    "        elif row.nnz > 0:\n",
    "            rows += [row_id] * row.nnz\n",
    "            cols += row.indices.tolist()\n",
    "            data += row.data.tolist()\n",
    "\n",
    "    topk_m = csr_matrix((data, (rows, cols)), (matrix.shape[0], matrix.shape[1]))\n",
    "\n",
    "    if axis == 0:\n",
    "        topk_m = topk_m.T.tocsr()\n",
    "\n",
    "    return topk_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `HR@10` для item-based CF модели, созданной автором блокнота: 0.085"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подcказки\n",
    "* Определитесь с тем, что вы пытаетесь предсказать (рейтинги, вероятности, ...)\n",
    "* Оптимальный способ вычисления матрицы схожести выглядит так:\n",
    " * Привести строки в матрице `user x item` к единичной длине (выделяет основные предпочтения пользователя)\n",
    " * Построить матрицу схожести `item x item`\n",
    " * Для каждого объекта оставить только $K$ наиболее похожих объектов\n",
    " * Для каждого объекта привести к единичной длине вектор схожести этого объекта (выделяет наиболее схожие объекты)\n",
    "* Удалили ли вы из рекомендаций объекты, которые пользователь уже оценивал?\n",
    "* Статья \"Item-Based Top-N Recommendation Algorithms\", Mukund Deshpande и George Karypis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Item-based collaborative filtering RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор модели обусловлен тем что Количество объектов: 10672, Количество пользователей: 24303 соответвенно нам лучше подойдет модель основанная на Item "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение матрицы схожести"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Удалим обькты которые имеют только одну оценку пользователя\n",
    "training_df=clean_df(training_df,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2051063261170754"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['rating'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_df=training_df[['uid', 'iid','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33761</th>\n",
       "      <td>13</td>\n",
       "      <td>1903</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43610</th>\n",
       "      <td>13</td>\n",
       "      <td>2455</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43823</th>\n",
       "      <td>13</td>\n",
       "      <td>2470</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70987</th>\n",
       "      <td>13</td>\n",
       "      <td>3872</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111232</th>\n",
       "      <td>13</td>\n",
       "      <td>5782</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146928</th>\n",
       "      <td>13</td>\n",
       "      <td>7156</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid   iid  rating\n",
       "33761    13  1903     5.0\n",
       "43610    13  2455     5.0\n",
       "43823    13  2470     3.0\n",
       "70987    13  3872     5.0\n",
       "111232   13  5782     5.0\n",
       "146928   13  7156     5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.query('uid==13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# для построениея user_item\n",
    "\n",
    "def load_data(df):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    \n",
    "    uid_to_row = {}\n",
    "    iid_to_col = {}\n",
    "    \n",
    "    for t in df.itertuples():\n",
    "        row_id = uid_to_row.setdefault(t.uid, len(uid_to_row))\n",
    "        col_id = iid_to_col.setdefault(t.iid, len(iid_to_col))\n",
    "        rating = t.rating\n",
    "        \n",
    "        rows.append(row_id)\n",
    "        cols.append(col_id)\n",
    "        data.append(rating)\n",
    "        \n",
    "    ui_m = csr_matrix((data, (rows, cols)))\n",
    "    return ui_m, uid_to_row, iid_to_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22215, 10098)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_m, uid_to_row, iid_to_col = load_data(training_df)\n",
    "ui_m.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# нормализуем по пользователям\n",
    "n_ui_m = normalize(ui_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  5.,  1.,  5.,  1.,  2.])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_m[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13245324,  0.66226618,  0.13245324,  0.66226618,  0.13245324,\n",
       "        0.26490647])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ui_m[0].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_avg_rating = ui_m.sum(axis=0) / binarize(ui_m).sum(axis=0)\n",
    "item_avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sigmas(ui_m, item_avg_rating):\n",
    "    n_ui_m = ui_m - binarize(ui_m).multiply(item_avg_rating)  # r_{ui} - \\bar{r}_i\n",
    "    n_ui_m.data = n_ui_m.data ** 2  # (r_{ui} - \\bar{r}_i)^2\n",
    "    n_ui_m_sum = n_ui_m.sum(axis=0)  # \\sum(r_{ui} - \\bar{r}_i)^2\n",
    "    ratings_per_item = binarize(ui_m).sum(axis=0)  # |U_{i}|\n",
    "    sigmas = np.sqrt(n_ui_m_sum / ratings_per_item)\n",
    "    return sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmas = get_sigmas(ui_m, item_avg_rating)\n",
    "sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inv_sigmas = 1 / sigmas\n",
    "z_score= (ui_m - binarize(ui_m).multiply(item_avg_rating)).multiply(inv_sigmas)\n",
    "z_score=z_score.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_ui_m=z_score\n",
    "n_ui_m = normalize(ui_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  0.75      ,   3.        ,   2.5       , ...,  15.        ,\n",
       "           7.5       ,   5.        ],\n",
       "        [  0.85      ,   3.4       ,   2.83333333, ...,  17.        ,\n",
       "           8.5       ,   5.66666667],\n",
       "        [  1.6       ,   6.4       ,   5.33333333, ...,  32.        ,\n",
       "          16.        ,  10.66666667],\n",
       "        ..., \n",
       "        [  0.25      ,   1.        ,   0.83333333, ...,   5.        ,\n",
       "           2.5       ,   1.66666667],\n",
       "        [  0.25      ,   1.        ,   0.83333333, ...,   5.        ,\n",
       "           2.5       ,   1.66666667],\n",
       "        [  0.25      ,   1.        ,   0.83333333, ...,   5.        ,\n",
       "           2.5       ,   1.66666667]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# мы хотим увидеть средний среди существующих рейтингов\n",
    "user_avg_rating = ui_m.sum(axis=1) / binarize(ui_m).sum(axis=0)\n",
    "user_avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_c = ui_m - binarize(ui_m).multiply(user_avg_rating)\n",
    "n_ui_m = normalize(m_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### матрица схожести Item-Item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# находим матрицу схожести item-item\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "ii_sim_m = cosine_similarity(n_ui_m.T, dense_output=False).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOP=30\n",
    "# храним только top-30\n",
    "ii_sim_m = nullify_main_diagonal(ii_sim_m)\n",
    "ii_sim_m = get_topk(ii_sim_m, TOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# нормализуем схожести\n",
    "ii_sim_m = normalize(ii_sim_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## построим предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>I bought this and the key didn't work.  It was...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1404086400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131223</th>\n",
       "      <td>13</td>\n",
       "      <td>6607</td>\n",
       "      <td>I used these replacement cables to repair a he...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1404086400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215998</th>\n",
       "      <td>13</td>\n",
       "      <td>10044</td>\n",
       "      <td>If there are any PC games that can rival both ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1389052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220011</th>\n",
       "      <td>13</td>\n",
       "      <td>10129</td>\n",
       "      <td>This expansion / DLC is a must-have for Civ 5....</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1404086400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        uid    iid                                             review  rating  \\\n",
       "13       13      0  I bought this and the key didn't work.  It was...     1.0   \n",
       "131223   13   6607  I used these replacement cables to repair a he...     5.0   \n",
       "215998   13  10044  If there are any PC games that can rival both ...     5.0   \n",
       "220011   13  10129  This expansion / DLC is a must-have for Civ 5....     5.0   \n",
       "\n",
       "                dt  \n",
       "13      1404086400  \n",
       "131223  1404086400  \n",
       "215998  1389052800  \n",
       "220011  1404086400  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.query('uid==13').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_to_iid = {col_id: iid for iid, col_id in iid_to_col.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recs(uid, top):\n",
    "    recs = {}\n",
    "    if uid in uid_to_row:\n",
    "        u_row_id = uid_to_row[uid]\n",
    "        \n",
    "        recsk = n_ui_m[u_row_id].dot(ii_sim_m.T)\n",
    "        \n",
    "        b_bnr=(binarize(n_ui_m[u_row_id])*100).tocsr()\n",
    "              \n",
    "        #recsk=recsk-b_bnr\n",
    "        \n",
    "        #iid_to_remove=training_df[training_df.uid==uid]['iid'].unique()\n",
    "        # и узнаем их количество\n",
    "        #cnt_tu_del=len(iid_to_remove)            \n",
    "\n",
    "        #sort_indices = np.argsort(recsk.data)[::-1]\n",
    "        \n",
    "        for arg_id in np.argsort(recsk.data)[-top:][::-1]:\n",
    "            iid = recsk.indices[arg_id]\n",
    "            riid=col_to_iid[iid]\n",
    "            score = recsk.data[arg_id]\n",
    "            #if riid not in iid_to_remove: \n",
    "            recs[riid] = score\n",
    "            #if len(recs)>=top:\n",
    "            #    return recs\n",
    "                  \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: 0.1529839419549861,\n",
       " 2338: 0.15225232413820744,\n",
       " 2339: 0.16965551556850625,\n",
       " 3598: 0.17756010950506632,\n",
       " 7917: 0.16911384687637765,\n",
       " 8314: 0.19075387755697742,\n",
       " 8821: 0.18504525495879684}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recs(13, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def get_batch_recs( uids, top):\n",
    "        return {uid: get_recs(uid, top) for uid in uids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rec_dict=get_batch_recs(test_df.uid,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04900953778429934"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тупо берем первые 10 по суммарным баллам за просмотр\n",
    "hit_ratio(rec_dict,test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Сделаем перебор по количеству попаданий из CF\n",
    "n_hr={}\n",
    "for i in range(4,10,1):\n",
    "    rec_dict=get_batch_recs(test_df.uid,i)\n",
    "    n_hr[i]=hit_ratio(rec_dict,test_dict)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# результат НК от максимума\n",
    "n_hr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант по умолчанию:  Храним 30,  HR:0.062"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 1:  Храним 30,  Z-score  HR: 0.062"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 2:  Храним 30,  Mean-centering  HR: 0.090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 3:  Храним 30,  Mean-centering + Удаление уже просмотренных  HR: 0.72 . странный результат, объяснить не могу, переделал по другому все равно   HR:0.073. хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 4:  Храним 50,  Mean-centering   HR: 0.089\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант 5:  Храним 20,  Mean-centering   HR: 0.089"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
